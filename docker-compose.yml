version: '3.8'

services:
  # PostgreSQL database for cognee
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: aiagent
      POSTGRES_USER: aiagent
      POSTGRES_PASSWORD: aiagent123
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U aiagent"]
      interval: 30s
      timeout: 10s
      retries: 3

  # GPT-OSS Service
  gpt-oss:
    build:
      context: .
      dockerfile: Dockerfile.gpt-oss
    ports:
      - "8000:8000"
    environment:
      - MODEL_NAME=gpt-oss
    volumes:
      - ./config:/app/config:ro
      - gpt_models:/models
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    depends_on:
      postgres:
        condition: service_healthy

  # Orchestrator Service
  orchestrator:
    build:
      context: .
      dockerfile: Dockerfile.orchestrator
    ports:
      - "8080:8080"
    environment:
      - LLM_API_KEY=${LLM_API_KEY:-your-key}
      - GPT_OSS_URL=http://gpt-oss:8000/v1/chat/completions
      - DATABASE_URL=postgresql://aiagent:aiagent123@postgres:5432/aiagent
      - GCS_BUCKET=${GCS_BUCKET:-ai-agent-repos}
      - PROJECT_ID=${PROJECT_ID:-ai-agent-project}
      - REGION=${REGION:-us-central1}
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - workspace_data:/workspace
      - ./config:/app/config:ro
    depends_on:
      postgres:
        condition: service_healthy
      gpt-oss:
        condition: service_healthy

  # Agent Template (for development)
  agent:
    build:
      context: .
      dockerfile: Dockerfile.agent
    ports:
      - "8081:8081"
    environment:
      - LLM_API_KEY=${LLM_API_KEY:-your-key}
      - GPT_OSS_URL=http://gpt-oss:8000/v1/chat/completions
      - WORKSPACE_ID=development
      - REPO_URL=${REPO_URL:-}
    volumes:
      - workspace_data:/workspace
      - ./config:/app/config:ro
    depends_on:
      gpt-oss:
        condition: service_healthy

  # LibreChat UI (optional)
  librechat:
    image: ghcr.io/danny-avila/librechat:latest
    ports:
      - "3080:3080"
    environment:
      - BACKEND_URL=http://orchestrator:8080
      - OPENAI_API_KEY=${LLM_API_KEY:-your-key}
      - CUSTOM_API_BASE=http://gpt-oss:8000/v1
    volumes:
      - librechat_data:/app/client/public/images
      - ./config/librechat.yaml:/app/librechat.yaml:ro
    depends_on:
      orchestrator:
        condition: service_started

volumes:
  postgres_data:
    driver: local
  workspace_data:
    driver: local
  gpt_models:
    driver: local
  librechat_data:
    driver: local

networks:
  default:
    name: ai-agent-network
    driver: bridge